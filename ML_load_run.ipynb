{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import WireDataset\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from ML import Net\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torchmetrics.classification import F1Score, MulticlassRecall, MulticlassConfusionMatrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = WireDataset(\"Input_Data.csv\")\n",
    "# TODO add to device\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = torch.Generator().manual_seed(4)\n",
    "\n",
    "train_fraction = math.floor(len(dataset)*0.7)\n",
    "test_fraction = len(dataset) - train_fraction\n",
    "\n",
    "test_data_ind, train_data_ind = torch.utils.data.random_split(dataset, [test_fraction, train_fraction], generator = generator)\n",
    "\n",
    "dl_train = DataLoader(train_data_ind, batch_size=20, shuffle=True) #todevice\n",
    "dl_test = DataLoader(test_data_ind, batch_size=20, shuffle=True) #todevice\n",
    "\n",
    "net = Net() #todevice\n",
    "#optimizer = torch.optim.SGD(net.parameters(), lr=0.0001)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_F1List = np.zeros((2, 100))\n",
    "F1= F1Score(\"multiclass\", num_classes = 6)\n",
    "f1_max = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    10] loss: 1.851\n",
      "[1,    20] loss: 1.836\n",
      "[1,    30] loss: 1.807\n",
      "[1,    40] loss: 1.781\n",
      "[1,    50] loss: 1.756\n",
      "[1,    60] loss: 1.727\n",
      "[1,    70] loss: 1.694\n",
      "[1,    80] loss: 1.670\n",
      "[1,    90] loss: 1.640\n",
      "[1,   100] loss: 1.636\n",
      "[1,   110] loss: 1.601\n",
      "[1,   120] loss: 1.602\n",
      "[batch 9, size: 20] F1 score: 0.30000001192092896\n",
      "[batch 19, size: 20] F1 score: 0.6000000238418579\n",
      "[batch 29, size: 20] F1 score: 0.5\n",
      "[batch 39, size: 20] F1 score: 0.30000001192092896\n",
      "[batch 49, size: 20] F1 score: 0.6000000238418579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,    10] loss: 1.542\n",
      "[2,    20] loss: 1.526\n",
      "[2,    30] loss: 1.500\n",
      "[2,    40] loss: 1.418\n",
      "[2,    50] loss: 1.411\n",
      "[2,    60] loss: 1.302\n",
      "[2,    70] loss: 1.272\n",
      "[2,    80] loss: 1.356\n",
      "[2,    90] loss: 1.364\n",
      "[2,   100] loss: 1.319\n",
      "[2,   110] loss: 1.250\n",
      "[2,   120] loss: 1.381\n",
      "[batch 9, size: 20] F1 score: 0.4000000059604645\n",
      "[batch 19, size: 20] F1 score: 0.5\n",
      "[batch 29, size: 20] F1 score: 0.6000000238418579\n",
      "[batch 39, size: 20] F1 score: 0.550000011920929\n",
      "[batch 49, size: 20] F1 score: 0.3499999940395355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3,    10] loss: 1.254\n",
      "[3,    20] loss: 1.238\n",
      "[3,    30] loss: 1.273\n",
      "[3,    40] loss: 1.218\n",
      "[3,    50] loss: 1.191\n",
      "[3,    60] loss: 1.205\n",
      "[3,    70] loss: 1.295\n",
      "[3,    80] loss: 1.184\n",
      "[3,    90] loss: 1.344\n",
      "[3,   100] loss: 1.192\n",
      "[3,   110] loss: 1.317\n",
      "[3,   120] loss: 1.287\n",
      "[batch 9, size: 20] F1 score: 0.6499999761581421\n",
      "[batch 19, size: 20] F1 score: 0.44999998807907104\n",
      "[batch 29, size: 20] F1 score: 0.6499999761581421\n",
      "[batch 39, size: 20] F1 score: 0.75\n",
      "[batch 49, size: 20] F1 score: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4,    10] loss: 1.149\n",
      "[4,    20] loss: 1.217\n",
      "[4,    30] loss: 1.226\n",
      "[4,    40] loss: 1.237\n",
      "[4,    50] loss: 1.217\n",
      "[4,    60] loss: 1.290\n",
      "[4,    70] loss: 1.251\n",
      "[4,    80] loss: 1.331\n",
      "[4,    90] loss: 1.265\n",
      "[4,   100] loss: 1.171\n",
      "[4,   110] loss: 1.216\n",
      "[4,   120] loss: 1.229\n",
      "[batch 9, size: 20] F1 score: 0.550000011920929\n",
      "[batch 19, size: 20] F1 score: 0.6000000238418579\n",
      "[batch 29, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 39, size: 20] F1 score: 0.4000000059604645\n",
      "[batch 49, size: 20] F1 score: 0.550000011920929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5,    10] loss: 1.134\n",
      "[5,    20] loss: 1.238\n",
      "[5,    30] loss: 1.199\n",
      "[5,    40] loss: 1.301\n",
      "[5,    50] loss: 1.271\n",
      "[5,    60] loss: 1.267\n",
      "[5,    70] loss: 1.324\n",
      "[5,    80] loss: 1.251\n",
      "[5,    90] loss: 1.304\n",
      "[5,   100] loss: 1.107\n",
      "[5,   110] loss: 1.167\n",
      "[5,   120] loss: 1.203\n",
      "[batch 9, size: 20] F1 score: 0.75\n",
      "[batch 19, size: 20] F1 score: 0.699999988079071\n",
      "[batch 29, size: 20] F1 score: 0.550000011920929\n",
      "[batch 39, size: 20] F1 score: 0.44999998807907104\n",
      "[batch 49, size: 20] F1 score: 0.800000011920929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6,    10] loss: 1.192\n",
      "[6,    20] loss: 1.228\n",
      "[6,    30] loss: 1.260\n",
      "[6,    40] loss: 1.207\n",
      "[6,    50] loss: 1.284\n",
      "[6,    60] loss: 1.144\n",
      "[6,    70] loss: 1.283\n",
      "[6,    80] loss: 1.218\n",
      "[6,    90] loss: 1.151\n",
      "[6,   100] loss: 1.145\n",
      "[6,   110] loss: 1.235\n",
      "[6,   120] loss: 1.221\n",
      "[batch 9, size: 20] F1 score: 0.6499999761581421\n",
      "[batch 19, size: 20] F1 score: 0.550000011920929\n",
      "[batch 29, size: 20] F1 score: 0.6000000238418579\n",
      "[batch 39, size: 20] F1 score: 0.6499999761581421\n",
      "[batch 49, size: 20] F1 score: 0.6000000238418579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7,    10] loss: 1.134\n",
      "[7,    20] loss: 1.276\n",
      "[7,    30] loss: 1.252\n",
      "[7,    40] loss: 1.171\n",
      "[7,    50] loss: 1.211\n",
      "[7,    60] loss: 1.088\n",
      "[7,    70] loss: 1.210\n",
      "[7,    80] loss: 1.361\n",
      "[7,    90] loss: 1.200\n",
      "[7,   100] loss: 1.284\n",
      "[7,   110] loss: 1.144\n",
      "[7,   120] loss: 1.145\n",
      "[batch 9, size: 20] F1 score: 0.550000011920929\n",
      "[batch 19, size: 20] F1 score: 0.550000011920929\n",
      "[batch 29, size: 20] F1 score: 0.550000011920929\n",
      "[batch 39, size: 20] F1 score: 0.5\n",
      "[batch 49, size: 20] F1 score: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8,    10] loss: 1.181\n",
      "[8,    20] loss: 1.206\n",
      "[8,    30] loss: 1.157\n",
      "[8,    40] loss: 1.198\n",
      "[8,    50] loss: 1.165\n",
      "[8,    60] loss: 1.293\n",
      "[8,    70] loss: 1.215\n",
      "[8,    80] loss: 1.314\n",
      "[8,    90] loss: 1.183\n",
      "[8,   100] loss: 1.170\n",
      "[8,   110] loss: 1.179\n",
      "[8,   120] loss: 1.172\n",
      "[batch 9, size: 20] F1 score: 0.3499999940395355\n",
      "[batch 19, size: 20] F1 score: 0.44999998807907104\n",
      "[batch 29, size: 20] F1 score: 0.3499999940395355\n",
      "[batch 39, size: 20] F1 score: 0.44999998807907104\n",
      "[batch 49, size: 20] F1 score: 0.6000000238418579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9,    10] loss: 1.135\n",
      "[9,    20] loss: 1.247\n",
      "[9,    30] loss: 1.228\n",
      "[9,    40] loss: 1.149\n",
      "[9,    50] loss: 1.220\n",
      "[9,    60] loss: 1.356\n",
      "[9,    70] loss: 1.101\n",
      "[9,    80] loss: 1.238\n",
      "[9,    90] loss: 1.196\n",
      "[9,   100] loss: 1.223\n",
      "[9,   110] loss: 1.158\n",
      "[9,   120] loss: 1.134\n",
      "[batch 9, size: 20] F1 score: 0.4000000059604645\n",
      "[batch 19, size: 20] F1 score: 0.6000000238418579\n",
      "[batch 29, size: 20] F1 score: 0.550000011920929\n",
      "[batch 39, size: 20] F1 score: 0.6000000238418579\n",
      "[batch 49, size: 20] F1 score: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10,    10] loss: 1.231\n",
      "[10,    20] loss: 1.117\n",
      "[10,    30] loss: 1.180\n",
      "[10,    40] loss: 1.275\n",
      "[10,    50] loss: 1.123\n",
      "[10,    60] loss: 1.199\n",
      "[10,    70] loss: 1.187\n",
      "[10,    80] loss: 1.291\n",
      "[10,    90] loss: 1.251\n",
      "[10,   100] loss: 1.276\n",
      "[10,   110] loss: 1.023\n",
      "[10,   120] loss: 1.114\n",
      "[batch 9, size: 20] F1 score: 0.5\n",
      "[batch 19, size: 20] F1 score: 0.44999998807907104\n",
      "[batch 29, size: 20] F1 score: 0.550000011920929\n",
      "[batch 39, size: 20] F1 score: 0.5\n",
      "[batch 49, size: 20] F1 score: 0.4000000059604645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11,    10] loss: 1.279\n",
      "[11,    20] loss: 1.126\n",
      "[11,    30] loss: 1.182\n",
      "[11,    40] loss: 1.220\n",
      "[11,    50] loss: 1.149\n",
      "[11,    60] loss: 1.230\n",
      "[11,    70] loss: 1.119\n",
      "[11,    80] loss: 1.269\n",
      "[11,    90] loss: 1.142\n",
      "[11,   100] loss: 1.104\n",
      "[11,   110] loss: 1.205\n",
      "[11,   120] loss: 1.099\n",
      "[batch 9, size: 20] F1 score: 0.699999988079071\n",
      "[batch 19, size: 20] F1 score: 0.550000011920929\n",
      "[batch 29, size: 20] F1 score: 0.550000011920929\n",
      "[batch 39, size: 20] F1 score: 0.550000011920929\n",
      "[batch 49, size: 20] F1 score: 0.550000011920929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12,    10] loss: 1.005\n",
      "[12,    20] loss: 0.997\n",
      "[12,    30] loss: 1.164\n",
      "[12,    40] loss: 1.158\n",
      "[12,    50] loss: 1.089\n",
      "[12,    60] loss: 1.146\n",
      "[12,    70] loss: 1.160\n",
      "[12,    80] loss: 1.136\n",
      "[12,    90] loss: 1.232\n",
      "[12,   100] loss: 1.018\n",
      "[12,   110] loss: 1.029\n",
      "[12,   120] loss: 1.090\n",
      "[batch 9, size: 20] F1 score: 0.699999988079071\n",
      "[batch 19, size: 20] F1 score: 0.550000011920929\n",
      "[batch 29, size: 20] F1 score: 0.6000000238418579\n",
      "[batch 39, size: 20] F1 score: 0.5\n",
      "[batch 49, size: 20] F1 score: 0.6499999761581421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13,    10] loss: 0.940\n",
      "[13,    20] loss: 1.006\n",
      "[13,    30] loss: 1.040\n",
      "[13,    40] loss: 1.043\n",
      "[13,    50] loss: 0.978\n",
      "[13,    60] loss: 1.000\n",
      "[13,    70] loss: 1.051\n",
      "[13,    80] loss: 0.944\n",
      "[13,    90] loss: 0.875\n",
      "[13,   100] loss: 0.870\n",
      "[13,   110] loss: 0.937\n",
      "[13,   120] loss: 0.872\n",
      "[batch 9, size: 20] F1 score: 0.75\n",
      "[batch 19, size: 20] F1 score: 0.550000011920929\n",
      "[batch 29, size: 20] F1 score: 0.75\n",
      "[batch 39, size: 20] F1 score: 0.699999988079071\n",
      "[batch 49, size: 20] F1 score: 0.6000000238418579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14,    10] loss: 0.818\n",
      "[14,    20] loss: 0.813\n",
      "[14,    30] loss: 0.823\n",
      "[14,    40] loss: 0.826\n",
      "[14,    50] loss: 0.896\n",
      "[14,    60] loss: 0.931\n",
      "[14,    70] loss: 0.881\n",
      "[14,    80] loss: 0.888\n",
      "[14,    90] loss: 0.834\n",
      "[14,   100] loss: 0.939\n",
      "[14,   110] loss: 0.852\n",
      "[14,   120] loss: 0.777\n",
      "[batch 9, size: 20] F1 score: 0.800000011920929\n",
      "[batch 19, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 29, size: 20] F1 score: 0.6499999761581421\n",
      "[batch 39, size: 20] F1 score: 0.75\n",
      "[batch 49, size: 20] F1 score: 0.949999988079071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15,    10] loss: 0.719\n",
      "[15,    20] loss: 0.726\n",
      "[15,    30] loss: 0.811\n",
      "[15,    40] loss: 0.725\n",
      "[15,    50] loss: 0.800\n",
      "[15,    60] loss: 0.836\n",
      "[15,    70] loss: 0.802\n",
      "[15,    80] loss: 0.830\n",
      "[15,    90] loss: 0.946\n",
      "[15,   100] loss: 0.752\n",
      "[15,   110] loss: 0.850\n",
      "[15,   120] loss: 0.955\n",
      "[batch 9, size: 20] F1 score: 0.699999988079071\n",
      "[batch 19, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 29, size: 20] F1 score: 0.800000011920929\n",
      "[batch 39, size: 20] F1 score: 0.800000011920929\n",
      "[batch 49, size: 20] F1 score: 0.8500000238418579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16,    10] loss: 0.734\n",
      "[16,    20] loss: 0.840\n",
      "[16,    30] loss: 0.902\n",
      "[16,    40] loss: 1.021\n",
      "[16,    50] loss: 0.772\n",
      "[16,    60] loss: 0.720\n",
      "[16,    70] loss: 0.761\n",
      "[16,    80] loss: 0.699\n",
      "[16,    90] loss: 0.730\n",
      "[16,   100] loss: 0.672\n",
      "[16,   110] loss: 0.704\n",
      "[16,   120] loss: 0.674\n",
      "[batch 9, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 19, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 29, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 39, size: 20] F1 score: 0.6499999761581421\n",
      "[batch 49, size: 20] F1 score: 0.800000011920929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17,    10] loss: 0.692\n",
      "[17,    20] loss: 0.697\n",
      "[17,    30] loss: 0.827\n",
      "[17,    40] loss: 0.696\n",
      "[17,    50] loss: 0.695\n",
      "[17,    60] loss: 0.639\n",
      "[17,    70] loss: 0.825\n",
      "[17,    80] loss: 0.704\n",
      "[17,    90] loss: 0.614\n",
      "[17,   100] loss: 0.692\n",
      "[17,   110] loss: 0.651\n",
      "[17,   120] loss: 0.694\n",
      "[batch 9, size: 20] F1 score: 0.699999988079071\n",
      "[batch 19, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 29, size: 20] F1 score: 0.800000011920929\n",
      "[batch 39, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 49, size: 20] F1 score: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18,    10] loss: 0.694\n",
      "[18,    20] loss: 0.650\n",
      "[18,    30] loss: 0.731\n",
      "[18,    40] loss: 0.513\n",
      "[18,    50] loss: 0.731\n",
      "[18,    60] loss: 0.597\n",
      "[18,    70] loss: 0.718\n",
      "[18,    80] loss: 0.656\n",
      "[18,    90] loss: 0.754\n",
      "[18,   100] loss: 0.637\n",
      "[18,   110] loss: 0.595\n",
      "[18,   120] loss: 0.561\n",
      "[batch 9, size: 20] F1 score: 0.800000011920929\n",
      "[batch 19, size: 20] F1 score: 0.800000011920929\n",
      "[batch 29, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 39, size: 20] F1 score: 0.75\n",
      "[batch 49, size: 20] F1 score: 0.699999988079071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19,    10] loss: 0.657\n",
      "[19,    20] loss: 0.702\n",
      "[19,    30] loss: 0.514\n",
      "[19,    40] loss: 0.575\n",
      "[19,    50] loss: 0.638\n",
      "[19,    60] loss: 0.644\n",
      "[19,    70] loss: 0.702\n",
      "[19,    80] loss: 0.621\n",
      "[19,    90] loss: 0.685\n",
      "[19,   100] loss: 0.686\n",
      "[19,   110] loss: 0.578\n",
      "[19,   120] loss: 0.642\n",
      "[batch 9, size: 20] F1 score: 0.800000011920929\n",
      "[batch 19, size: 20] F1 score: 0.699999988079071\n",
      "[batch 29, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 39, size: 20] F1 score: 0.75\n",
      "[batch 49, size: 20] F1 score: 0.800000011920929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20,    10] loss: 0.542\n",
      "[20,    20] loss: 0.521\n",
      "[20,    30] loss: 0.633\n",
      "[20,    40] loss: 0.586\n",
      "[20,    50] loss: 0.633\n",
      "[20,    60] loss: 0.567\n",
      "[20,    70] loss: 0.587\n",
      "[20,    80] loss: 0.641\n",
      "[20,    90] loss: 0.564\n",
      "[20,   100] loss: 0.564\n",
      "[20,   110] loss: 0.522\n",
      "[20,   120] loss: 0.661\n",
      "[batch 9, size: 20] F1 score: 0.800000011920929\n",
      "[batch 19, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 29, size: 20] F1 score: 0.75\n",
      "[batch 39, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 49, size: 20] F1 score: 0.949999988079071\n",
      "[21,    10] loss: 0.606\n",
      "[21,    20] loss: 0.580\n",
      "[21,    30] loss: 0.600\n",
      "[21,    40] loss: 0.474\n",
      "[21,    50] loss: 0.453\n",
      "[21,    60] loss: 0.417\n",
      "[21,    70] loss: 0.510\n",
      "[21,    80] loss: 0.572\n",
      "[21,    90] loss: 0.558\n",
      "[21,   100] loss: 0.487\n",
      "[21,   110] loss: 0.640\n",
      "[21,   120] loss: 0.606\n",
      "[batch 9, size: 20] F1 score: 0.949999988079071\n",
      "[batch 19, size: 20] F1 score: 0.75\n",
      "[batch 29, size: 20] F1 score: 0.800000011920929\n",
      "[batch 39, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 49, size: 20] F1 score: 0.8500000238418579\n",
      "[22,    10] loss: 0.618\n",
      "[22,    20] loss: 0.550\n",
      "[22,    30] loss: 0.500\n",
      "[22,    40] loss: 0.495\n",
      "[22,    50] loss: 0.407\n",
      "[22,    60] loss: 0.461\n",
      "[22,    70] loss: 0.433\n",
      "[22,    80] loss: 0.549\n",
      "[22,    90] loss: 0.488\n",
      "[22,   100] loss: 0.514\n",
      "[22,   110] loss: 0.496\n",
      "[22,   120] loss: 0.591\n",
      "[batch 9, size: 20] F1 score: 0.949999988079071\n",
      "[batch 19, size: 20] F1 score: 0.800000011920929\n",
      "[batch 29, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 39, size: 20] F1 score: 0.800000011920929\n",
      "[batch 49, size: 20] F1 score: 0.75\n",
      "[23,    10] loss: 0.449\n",
      "[23,    20] loss: 0.474\n",
      "[23,    30] loss: 0.598\n",
      "[23,    40] loss: 0.466\n",
      "[23,    50] loss: 0.483\n",
      "[23,    60] loss: 0.464\n",
      "[23,    70] loss: 0.481\n",
      "[23,    80] loss: 0.473\n",
      "[23,    90] loss: 0.438\n",
      "[23,   100] loss: 0.577\n",
      "[23,   110] loss: 0.581\n",
      "[23,   120] loss: 0.508\n",
      "[batch 9, size: 20] F1 score: 0.699999988079071\n",
      "[batch 19, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 29, size: 20] F1 score: 0.800000011920929\n",
      "[batch 39, size: 20] F1 score: 0.949999988079071\n",
      "[batch 49, size: 20] F1 score: 0.699999988079071\n",
      "[24,    10] loss: 0.501\n",
      "[24,    20] loss: 0.534\n",
      "[24,    30] loss: 0.525\n",
      "[24,    40] loss: 0.426\n",
      "[24,    50] loss: 0.464\n",
      "[24,    60] loss: 0.381\n",
      "[24,    70] loss: 0.545\n",
      "[24,    80] loss: 0.436\n",
      "[24,    90] loss: 0.401\n",
      "[24,   100] loss: 0.441\n",
      "[24,   110] loss: 0.368\n",
      "[24,   120] loss: 0.594\n",
      "[batch 9, size: 20] F1 score: 1.0\n",
      "[batch 19, size: 20] F1 score: 0.6499999761581421\n",
      "[batch 29, size: 20] F1 score: 0.800000011920929\n",
      "[batch 39, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 49, size: 20] F1 score: 0.800000011920929\n",
      "[25,    10] loss: 0.467\n",
      "[25,    20] loss: 0.363\n",
      "[25,    30] loss: 0.455\n",
      "[25,    40] loss: 0.521\n",
      "[25,    50] loss: 0.387\n",
      "[25,    60] loss: 0.406\n",
      "[25,    70] loss: 0.471\n",
      "[25,    80] loss: 0.342\n",
      "[25,    90] loss: 0.404\n",
      "[25,   100] loss: 0.464\n",
      "[25,   110] loss: 0.473\n",
      "[25,   120] loss: 0.506\n",
      "[batch 9, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 19, size: 20] F1 score: 0.800000011920929\n",
      "[batch 29, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 39, size: 20] F1 score: 0.800000011920929\n",
      "[batch 49, size: 20] F1 score: 0.800000011920929\n",
      "[26,    10] loss: 0.406\n",
      "[26,    20] loss: 0.385\n",
      "[26,    30] loss: 0.404\n",
      "[26,    40] loss: 0.444\n",
      "[26,    50] loss: 0.413\n",
      "[26,    60] loss: 0.443\n",
      "[26,    70] loss: 0.448\n",
      "[26,    80] loss: 0.394\n",
      "[26,    90] loss: 0.542\n",
      "[26,   100] loss: 0.412\n",
      "[26,   110] loss: 0.376\n",
      "[26,   120] loss: 0.441\n",
      "[batch 9, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 19, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 29, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 39, size: 20] F1 score: 0.75\n",
      "[batch 49, size: 20] F1 score: 0.8500000238418579\n",
      "[27,    10] loss: 0.389\n",
      "[27,    20] loss: 0.430\n",
      "[27,    30] loss: 0.418\n",
      "[27,    40] loss: 0.461\n",
      "[27,    50] loss: 0.371\n",
      "[27,    60] loss: 0.402\n",
      "[27,    70] loss: 0.523\n",
      "[27,    80] loss: 0.379\n",
      "[27,    90] loss: 0.395\n",
      "[27,   100] loss: 0.435\n",
      "[27,   110] loss: 0.373\n",
      "[27,   120] loss: 0.435\n",
      "[batch 9, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 19, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 29, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 39, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 49, size: 20] F1 score: 0.949999988079071\n",
      "[28,    10] loss: 0.356\n",
      "[28,    20] loss: 0.321\n",
      "[28,    30] loss: 0.416\n",
      "[28,    40] loss: 0.227\n",
      "[28,    50] loss: 0.348\n",
      "[28,    60] loss: 0.448\n",
      "[28,    70] loss: 0.518\n",
      "[28,    80] loss: 0.466\n",
      "[28,    90] loss: 0.312\n",
      "[28,   100] loss: 0.531\n",
      "[28,   110] loss: 0.346\n",
      "[28,   120] loss: 0.503\n",
      "[batch 9, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 19, size: 20] F1 score: 0.699999988079071\n",
      "[batch 29, size: 20] F1 score: 1.0\n",
      "[batch 39, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 49, size: 20] F1 score: 1.0\n",
      "[29,    10] loss: 0.586\n",
      "[29,    20] loss: 0.354\n",
      "[29,    30] loss: 0.380\n",
      "[29,    40] loss: 0.385\n",
      "[29,    50] loss: 0.395\n",
      "[29,    60] loss: 0.368\n",
      "[29,    70] loss: 0.342\n",
      "[29,    80] loss: 0.410\n",
      "[29,    90] loss: 0.343\n",
      "[29,   100] loss: 0.403\n",
      "[29,   110] loss: 0.338\n",
      "[29,   120] loss: 0.346\n",
      "[batch 9, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 19, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 29, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 39, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 49, size: 20] F1 score: 0.800000011920929\n",
      "[30,    10] loss: 0.370\n",
      "[30,    20] loss: 0.406\n",
      "[30,    30] loss: 0.344\n",
      "[30,    40] loss: 0.409\n",
      "[30,    50] loss: 0.303\n",
      "[30,    60] loss: 0.276\n",
      "[30,    70] loss: 0.425\n",
      "[30,    80] loss: 0.368\n",
      "[30,    90] loss: 0.332\n",
      "[30,   100] loss: 0.279\n",
      "[30,   110] loss: 0.363\n",
      "[30,   120] loss: 0.399\n",
      "[batch 9, size: 20] F1 score: 0.949999988079071\n",
      "[batch 19, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 29, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 39, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 49, size: 20] F1 score: 0.8999999761581421\n",
      "[31,    10] loss: 0.349\n",
      "[31,    20] loss: 0.368\n",
      "[31,    30] loss: 0.334\n",
      "[31,    40] loss: 0.338\n",
      "[31,    50] loss: 0.410\n",
      "[31,    60] loss: 0.348\n",
      "[31,    70] loss: 0.344\n",
      "[31,    80] loss: 0.362\n",
      "[31,    90] loss: 0.300\n",
      "[31,   100] loss: 0.338\n",
      "[31,   110] loss: 0.363\n",
      "[31,   120] loss: 0.341\n",
      "[batch 9, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 19, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 29, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 39, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 49, size: 20] F1 score: 0.949999988079071\n",
      "[32,    10] loss: 0.408\n",
      "[32,    20] loss: 0.296\n",
      "[32,    30] loss: 0.275\n",
      "[32,    40] loss: 0.265\n",
      "[32,    50] loss: 0.394\n",
      "[32,    60] loss: 0.292\n",
      "[32,    70] loss: 0.267\n",
      "[32,    80] loss: 0.363\n",
      "[32,    90] loss: 0.338\n",
      "[32,   100] loss: 0.322\n",
      "[32,   110] loss: 0.309\n",
      "[32,   120] loss: 0.386\n",
      "[batch 9, size: 20] F1 score: 1.0\n",
      "[batch 19, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 29, size: 20] F1 score: 0.75\n",
      "[batch 39, size: 20] F1 score: 1.0\n",
      "[batch 49, size: 20] F1 score: 0.8500000238418579\n",
      "[33,    10] loss: 0.304\n",
      "[33,    20] loss: 0.353\n",
      "[33,    30] loss: 0.378\n",
      "[33,    40] loss: 0.419\n",
      "[33,    50] loss: 0.444\n",
      "[33,    60] loss: 0.367\n",
      "[33,    70] loss: 0.425\n",
      "[33,    80] loss: 0.268\n",
      "[33,    90] loss: 0.289\n",
      "[33,   100] loss: 0.303\n",
      "[33,   110] loss: 0.260\n",
      "[33,   120] loss: 0.294\n",
      "[batch 9, size: 20] F1 score: 1.0\n",
      "[batch 19, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 29, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 39, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 49, size: 20] F1 score: 0.949999988079071\n",
      "[34,    10] loss: 0.307\n",
      "[34,    20] loss: 0.360\n",
      "[34,    30] loss: 0.321\n",
      "[34,    40] loss: 0.175\n",
      "[34,    50] loss: 0.462\n",
      "[34,    60] loss: 0.273\n",
      "[34,    70] loss: 0.331\n",
      "[34,    80] loss: 0.293\n",
      "[34,    90] loss: 0.328\n",
      "[34,   100] loss: 0.326\n",
      "[34,   110] loss: 0.411\n",
      "[34,   120] loss: 0.339\n",
      "[batch 9, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 19, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 29, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 39, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 49, size: 20] F1 score: 1.0\n",
      "[35,    10] loss: 0.273\n",
      "[35,    20] loss: 0.282\n",
      "[35,    30] loss: 0.380\n",
      "[35,    40] loss: 0.284\n",
      "[35,    50] loss: 0.267\n",
      "[35,    60] loss: 0.220\n",
      "[35,    70] loss: 0.280\n",
      "[35,    80] loss: 0.317\n",
      "[35,    90] loss: 0.294\n",
      "[35,   100] loss: 0.303\n",
      "[35,   110] loss: 0.265\n",
      "[35,   120] loss: 0.284\n",
      "[batch 9, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 19, size: 20] F1 score: 0.800000011920929\n",
      "[batch 29, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 39, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 49, size: 20] F1 score: 0.8999999761581421\n",
      "[36,    10] loss: 0.287\n",
      "[36,    20] loss: 0.311\n",
      "[36,    30] loss: 0.307\n",
      "[36,    40] loss: 0.216\n",
      "[36,    50] loss: 0.322\n",
      "[36,    60] loss: 0.260\n",
      "[36,    70] loss: 0.179\n",
      "[36,    80] loss: 0.300\n",
      "[36,    90] loss: 0.329\n",
      "[36,   100] loss: 0.295\n",
      "[36,   110] loss: 0.348\n",
      "[36,   120] loss: 0.340\n",
      "[batch 9, size: 20] F1 score: 1.0\n",
      "[batch 19, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 29, size: 20] F1 score: 0.949999988079071\n",
      "[batch 39, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 49, size: 20] F1 score: 0.8999999761581421\n",
      "[37,    10] loss: 0.252\n",
      "[37,    20] loss: 0.248\n",
      "[37,    30] loss: 0.309\n",
      "[37,    40] loss: 0.277\n",
      "[37,    50] loss: 0.288\n",
      "[37,    60] loss: 0.177\n",
      "[37,    70] loss: 0.221\n",
      "[37,    80] loss: 0.213\n",
      "[37,    90] loss: 0.269\n",
      "[37,   100] loss: 0.299\n",
      "[37,   110] loss: 0.346\n",
      "[37,   120] loss: 0.345\n",
      "[batch 9, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 19, size: 20] F1 score: 0.949999988079071\n",
      "[batch 29, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 39, size: 20] F1 score: 0.75\n",
      "[batch 49, size: 20] F1 score: 0.8999999761581421\n",
      "[38,    10] loss: 0.254\n",
      "[38,    20] loss: 0.322\n",
      "[38,    30] loss: 0.292\n",
      "[38,    40] loss: 0.208\n",
      "[38,    50] loss: 0.271\n",
      "[38,    60] loss: 0.293\n",
      "[38,    70] loss: 0.214\n",
      "[38,    80] loss: 0.235\n",
      "[38,    90] loss: 0.320\n",
      "[38,   100] loss: 0.254\n",
      "[38,   110] loss: 0.283\n",
      "[38,   120] loss: 0.254\n",
      "[batch 9, size: 20] F1 score: 0.800000011920929\n",
      "[batch 19, size: 20] F1 score: 0.949999988079071\n",
      "[batch 29, size: 20] F1 score: 0.699999988079071\n",
      "[batch 39, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 49, size: 20] F1 score: 0.8500000238418579\n",
      "[39,    10] loss: 0.258\n",
      "[39,    20] loss: 0.268\n",
      "[39,    30] loss: 0.221\n",
      "[39,    40] loss: 0.283\n",
      "[39,    50] loss: 0.293\n",
      "[39,    60] loss: 0.265\n",
      "[39,    70] loss: 0.247\n",
      "[39,    80] loss: 0.236\n",
      "[39,    90] loss: 0.262\n",
      "[39,   100] loss: 0.224\n",
      "[39,   110] loss: 0.269\n",
      "[39,   120] loss: 0.241\n",
      "[batch 9, size: 20] F1 score: 0.949999988079071\n",
      "[batch 19, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 29, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 39, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 49, size: 20] F1 score: 0.75\n",
      "[40,    10] loss: 0.225\n",
      "[40,    20] loss: 0.206\n",
      "[40,    30] loss: 0.224\n",
      "[40,    40] loss: 0.275\n",
      "[40,    50] loss: 0.327\n",
      "[40,    60] loss: 0.305\n",
      "[40,    70] loss: 0.289\n",
      "[40,    80] loss: 0.206\n",
      "[40,    90] loss: 0.255\n",
      "[40,   100] loss: 0.328\n",
      "[40,   110] loss: 0.319\n",
      "[40,   120] loss: 0.244\n",
      "[batch 9, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 19, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 29, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 39, size: 20] F1 score: 0.949999988079071\n",
      "[batch 49, size: 20] F1 score: 0.949999988079071\n",
      "[41,    10] loss: 0.253\n",
      "[41,    20] loss: 0.262\n",
      "[41,    30] loss: 0.183\n",
      "[41,    40] loss: 0.277\n",
      "[41,    50] loss: 0.360\n",
      "[41,    60] loss: 0.334\n",
      "[41,    70] loss: 0.239\n",
      "[41,    80] loss: 0.211\n",
      "[41,    90] loss: 0.177\n",
      "[41,   100] loss: 0.215\n",
      "[41,   110] loss: 0.279\n",
      "[41,   120] loss: 0.273\n",
      "[batch 9, size: 20] F1 score: 0.949999988079071\n",
      "[batch 19, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 29, size: 20] F1 score: 0.800000011920929\n",
      "[batch 39, size: 20] F1 score: 0.800000011920929\n",
      "[batch 49, size: 20] F1 score: 0.800000011920929\n",
      "[42,    10] loss: 0.170\n",
      "[42,    20] loss: 0.182\n",
      "[42,    30] loss: 0.315\n",
      "[42,    40] loss: 0.257\n",
      "[42,    50] loss: 0.209\n",
      "[42,    60] loss: 0.280\n",
      "[42,    70] loss: 0.221\n",
      "[42,    80] loss: 0.235\n",
      "[42,    90] loss: 0.258\n",
      "[42,   100] loss: 0.233\n",
      "[42,   110] loss: 0.345\n",
      "[42,   120] loss: 0.323\n",
      "[batch 9, size: 20] F1 score: 0.949999988079071\n",
      "[batch 19, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 29, size: 20] F1 score: 0.949999988079071\n",
      "[batch 39, size: 20] F1 score: 0.75\n",
      "[batch 49, size: 20] F1 score: 0.8500000238418579\n",
      "[43,    10] loss: 0.226\n",
      "[43,    20] loss: 0.250\n",
      "[43,    30] loss: 0.240\n",
      "[43,    40] loss: 0.234\n",
      "[43,    50] loss: 0.185\n",
      "[43,    60] loss: 0.209\n",
      "[43,    70] loss: 0.280\n",
      "[43,    80] loss: 0.262\n",
      "[43,    90] loss: 0.276\n",
      "[43,   100] loss: 0.271\n",
      "[43,   110] loss: 0.154\n",
      "[43,   120] loss: 0.244\n",
      "[batch 9, size: 20] F1 score: 0.949999988079071\n",
      "[batch 19, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 29, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 39, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 49, size: 20] F1 score: 0.8500000238418579\n",
      "[44,    10] loss: 0.137\n",
      "[44,    20] loss: 0.240\n",
      "[44,    30] loss: 0.272\n",
      "[44,    40] loss: 0.174\n",
      "[44,    50] loss: 0.229\n",
      "[44,    60] loss: 0.196\n",
      "[44,    70] loss: 0.235\n",
      "[44,    80] loss: 0.192\n",
      "[44,    90] loss: 0.271\n",
      "[44,   100] loss: 0.232\n",
      "[44,   110] loss: 0.233\n",
      "[44,   120] loss: 0.260\n",
      "[batch 9, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 19, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 29, size: 20] F1 score: 1.0\n",
      "[batch 39, size: 20] F1 score: 0.949999988079071\n",
      "[batch 49, size: 20] F1 score: 0.949999988079071\n",
      "[45,    10] loss: 0.248\n",
      "[45,    20] loss: 0.239\n",
      "[45,    30] loss: 0.172\n",
      "[45,    40] loss: 0.184\n",
      "[45,    50] loss: 0.144\n",
      "[45,    60] loss: 0.162\n",
      "[45,    70] loss: 0.171\n",
      "[45,    80] loss: 0.172\n",
      "[45,    90] loss: 0.202\n",
      "[45,   100] loss: 0.207\n",
      "[45,   110] loss: 0.226\n",
      "[45,   120] loss: 0.249\n",
      "[batch 9, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 19, size: 20] F1 score: 0.949999988079071\n",
      "[batch 29, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 39, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 49, size: 20] F1 score: 0.949999988079071\n",
      "[46,    10] loss: 0.161\n",
      "[46,    20] loss: 0.239\n",
      "[46,    30] loss: 0.142\n",
      "[46,    40] loss: 0.176\n",
      "[46,    50] loss: 0.179\n",
      "[46,    60] loss: 0.194\n",
      "[46,    70] loss: 0.227\n",
      "[46,    80] loss: 0.227\n",
      "[46,    90] loss: 0.203\n",
      "[46,   100] loss: 0.270\n",
      "[46,   110] loss: 0.232\n",
      "[46,   120] loss: 0.250\n",
      "[batch 9, size: 20] F1 score: 0.800000011920929\n",
      "[batch 19, size: 20] F1 score: 0.800000011920929\n",
      "[batch 29, size: 20] F1 score: 0.800000011920929\n",
      "[batch 39, size: 20] F1 score: 1.0\n",
      "[batch 49, size: 20] F1 score: 0.75\n",
      "[47,    10] loss: 0.249\n",
      "[47,    20] loss: 0.279\n",
      "[47,    30] loss: 0.194\n",
      "[47,    40] loss: 0.138\n",
      "[47,    50] loss: 0.207\n",
      "[47,    60] loss: 0.164\n",
      "[47,    70] loss: 0.212\n",
      "[47,    80] loss: 0.167\n",
      "[47,    90] loss: 0.200\n",
      "[47,   100] loss: 0.191\n",
      "[47,   110] loss: 0.148\n",
      "[47,   120] loss: 0.294\n",
      "[batch 9, size: 20] F1 score: 0.800000011920929\n",
      "[batch 19, size: 20] F1 score: 0.800000011920929\n",
      "[batch 29, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 39, size: 20] F1 score: 0.75\n",
      "[batch 49, size: 20] F1 score: 0.8999999761581421\n",
      "[48,    10] loss: 0.240\n",
      "[48,    20] loss: 0.180\n",
      "[48,    30] loss: 0.181\n",
      "[48,    40] loss: 0.183\n",
      "[48,    50] loss: 0.155\n",
      "[48,    60] loss: 0.271\n",
      "[48,    70] loss: 0.228\n",
      "[48,    80] loss: 0.206\n",
      "[48,    90] loss: 0.202\n",
      "[48,   100] loss: 0.170\n",
      "[48,   110] loss: 0.222\n",
      "[48,   120] loss: 0.142\n",
      "[batch 9, size: 20] F1 score: 0.699999988079071\n",
      "[batch 19, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 29, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 39, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 49, size: 20] F1 score: 0.8999999761581421\n",
      "[49,    10] loss: 0.178\n",
      "[49,    20] loss: 0.227\n",
      "[49,    30] loss: 0.156\n",
      "[49,    40] loss: 0.113\n",
      "[49,    50] loss: 0.155\n",
      "[49,    60] loss: 0.123\n",
      "[49,    70] loss: 0.136\n",
      "[49,    80] loss: 0.200\n",
      "[49,    90] loss: 0.209\n",
      "[49,   100] loss: 0.101\n",
      "[49,   110] loss: 0.190\n",
      "[49,   120] loss: 0.176\n",
      "[batch 9, size: 20] F1 score: 0.949999988079071\n",
      "[batch 19, size: 20] F1 score: 0.800000011920929\n",
      "[batch 29, size: 20] F1 score: 0.800000011920929\n",
      "[batch 39, size: 20] F1 score: 0.949999988079071\n",
      "[batch 49, size: 20] F1 score: 0.949999988079071\n",
      "[50,    10] loss: 0.180\n",
      "[50,    20] loss: 0.229\n",
      "[50,    30] loss: 0.145\n",
      "[50,    40] loss: 0.188\n",
      "[50,    50] loss: 0.167\n",
      "[50,    60] loss: 0.147\n",
      "[50,    70] loss: 0.175\n",
      "[50,    80] loss: 0.155\n",
      "[50,    90] loss: 0.141\n",
      "[50,   100] loss: 0.189\n",
      "[50,   110] loss: 0.121\n",
      "[50,   120] loss: 0.201\n",
      "[batch 9, size: 20] F1 score: 0.800000011920929\n",
      "[batch 19, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 29, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 39, size: 20] F1 score: 0.949999988079071\n",
      "[batch 49, size: 20] F1 score: 0.949999988079071\n",
      "[51,    10] loss: 0.123\n",
      "[51,    20] loss: 0.187\n",
      "[51,    30] loss: 0.180\n",
      "[51,    40] loss: 0.131\n",
      "[51,    50] loss: 0.144\n",
      "[51,    60] loss: 0.177\n",
      "[51,    70] loss: 0.166\n",
      "[51,    80] loss: 0.168\n",
      "[51,    90] loss: 0.231\n",
      "[51,   100] loss: 0.139\n",
      "[51,   110] loss: 0.115\n",
      "[51,   120] loss: 0.172\n",
      "[batch 9, size: 20] F1 score: 1.0\n",
      "[batch 19, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 29, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 39, size: 20] F1 score: 1.0\n",
      "[batch 49, size: 20] F1 score: 0.949999988079071\n",
      "[52,    10] loss: 0.167\n",
      "[52,    20] loss: 0.118\n",
      "[52,    30] loss: 0.104\n",
      "[52,    40] loss: 0.166\n",
      "[52,    50] loss: 0.191\n",
      "[52,    60] loss: 0.132\n",
      "[52,    70] loss: 0.140\n",
      "[52,    80] loss: 0.214\n",
      "[52,    90] loss: 0.161\n",
      "[52,   100] loss: 0.157\n",
      "[52,   110] loss: 0.182\n",
      "[52,   120] loss: 0.092\n",
      "[batch 9, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 19, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 29, size: 20] F1 score: 0.949999988079071\n",
      "[batch 39, size: 20] F1 score: 0.75\n",
      "[batch 49, size: 20] F1 score: 0.800000011920929\n",
      "[53,    10] loss: 0.139\n",
      "[53,    20] loss: 0.101\n",
      "[53,    30] loss: 0.241\n",
      "[53,    40] loss: 0.156\n",
      "[53,    50] loss: 0.135\n",
      "[53,    60] loss: 0.179\n",
      "[53,    70] loss: 0.107\n",
      "[53,    80] loss: 0.142\n",
      "[53,    90] loss: 0.216\n",
      "[53,   100] loss: 0.166\n",
      "[53,   110] loss: 0.195\n",
      "[53,   120] loss: 0.175\n",
      "[batch 9, size: 20] F1 score: 1.0\n",
      "[batch 19, size: 20] F1 score: 1.0\n",
      "[batch 29, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 39, size: 20] F1 score: 1.0\n",
      "[batch 49, size: 20] F1 score: 0.8500000238418579\n",
      "[54,    10] loss: 0.133\n",
      "[54,    20] loss: 0.205\n",
      "[54,    30] loss: 0.189\n",
      "[54,    40] loss: 0.141\n",
      "[54,    50] loss: 0.157\n",
      "[54,    60] loss: 0.150\n",
      "[54,    70] loss: 0.110\n",
      "[54,    80] loss: 0.225\n",
      "[54,    90] loss: 0.104\n",
      "[54,   100] loss: 0.186\n",
      "[54,   110] loss: 0.179\n",
      "[54,   120] loss: 0.091\n",
      "[batch 9, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 19, size: 20] F1 score: 0.949999988079071\n",
      "[batch 29, size: 20] F1 score: 0.800000011920929\n",
      "[batch 39, size: 20] F1 score: 0.949999988079071\n",
      "[batch 49, size: 20] F1 score: 0.8999999761581421\n",
      "[55,    10] loss: 0.113\n",
      "[55,    20] loss: 0.123\n",
      "[55,    30] loss: 0.198\n",
      "[55,    40] loss: 0.091\n",
      "[55,    50] loss: 0.135\n",
      "[55,    60] loss: 0.109\n",
      "[55,    70] loss: 0.169\n",
      "[55,    80] loss: 0.189\n",
      "[55,    90] loss: 0.157\n",
      "[55,   100] loss: 0.145\n",
      "[55,   110] loss: 0.142\n",
      "[55,   120] loss: 0.099\n",
      "[batch 9, size: 20] F1 score: 0.800000011920929\n",
      "[batch 19, size: 20] F1 score: 0.949999988079071\n",
      "[batch 29, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 39, size: 20] F1 score: 0.949999988079071\n",
      "[batch 49, size: 20] F1 score: 0.8500000238418579\n",
      "[56,    10] loss: 0.134\n",
      "[56,    20] loss: 0.117\n",
      "[56,    30] loss: 0.133\n",
      "[56,    40] loss: 0.082\n",
      "[56,    50] loss: 0.111\n",
      "[56,    60] loss: 0.239\n",
      "[56,    70] loss: 0.177\n",
      "[56,    80] loss: 0.093\n",
      "[56,    90] loss: 0.211\n",
      "[56,   100] loss: 0.143\n",
      "[56,   110] loss: 0.125\n",
      "[56,   120] loss: 0.116\n",
      "[batch 9, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 19, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 29, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 39, size: 20] F1 score: 0.800000011920929\n",
      "[batch 49, size: 20] F1 score: 0.75\n",
      "[57,    10] loss: 0.167\n",
      "[57,    20] loss: 0.069\n",
      "[57,    30] loss: 0.222\n",
      "[57,    40] loss: 0.162\n",
      "[57,    50] loss: 0.167\n",
      "[57,    60] loss: 0.099\n",
      "[57,    70] loss: 0.190\n",
      "[57,    80] loss: 0.153\n",
      "[57,    90] loss: 0.121\n",
      "[57,   100] loss: 0.160\n",
      "[57,   110] loss: 0.119\n",
      "[57,   120] loss: 0.154\n",
      "[batch 9, size: 20] F1 score: 0.800000011920929\n",
      "[batch 19, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 29, size: 20] F1 score: 0.949999988079071\n",
      "[batch 39, size: 20] F1 score: 1.0\n",
      "[batch 49, size: 20] F1 score: 0.8500000238418579\n",
      "[58,    10] loss: 0.112\n",
      "[58,    20] loss: 0.100\n",
      "[58,    30] loss: 0.109\n",
      "[58,    40] loss: 0.146\n",
      "[58,    50] loss: 0.147\n",
      "[58,    60] loss: 0.139\n",
      "[58,    70] loss: 0.134\n",
      "[58,    80] loss: 0.130\n",
      "[58,    90] loss: 0.125\n",
      "[58,   100] loss: 0.128\n",
      "[58,   110] loss: 0.142\n",
      "[58,   120] loss: 0.156\n",
      "[batch 9, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 19, size: 20] F1 score: 1.0\n",
      "[batch 29, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 39, size: 20] F1 score: 0.75\n",
      "[batch 49, size: 20] F1 score: 0.75\n",
      "[59,    10] loss: 0.097\n",
      "[59,    20] loss: 0.200\n",
      "[59,    30] loss: 0.132\n",
      "[59,    40] loss: 0.119\n",
      "[59,    50] loss: 0.105\n",
      "[59,    60] loss: 0.182\n",
      "[59,    70] loss: 0.124\n",
      "[59,    80] loss: 0.189\n",
      "[59,    90] loss: 0.213\n",
      "[59,   100] loss: 0.267\n",
      "[59,   110] loss: 0.208\n",
      "[59,   120] loss: 0.140\n",
      "[batch 9, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 19, size: 20] F1 score: 0.800000011920929\n",
      "[batch 29, size: 20] F1 score: 0.949999988079071\n",
      "[batch 39, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 49, size: 20] F1 score: 0.949999988079071\n",
      "[60,    10] loss: 0.114\n",
      "[60,    20] loss: 0.098\n",
      "[60,    30] loss: 0.102\n",
      "[60,    40] loss: 0.119\n",
      "[60,    50] loss: 0.155\n",
      "[60,    60] loss: 0.150\n",
      "[60,    70] loss: 0.066\n",
      "[60,    80] loss: 0.089\n",
      "[60,    90] loss: 0.184\n",
      "[60,   100] loss: 0.151\n",
      "[60,   110] loss: 0.116\n",
      "[60,   120] loss: 0.143\n",
      "[batch 9, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 19, size: 20] F1 score: 1.0\n",
      "[batch 29, size: 20] F1 score: 0.949999988079071\n",
      "[batch 39, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 49, size: 20] F1 score: 0.8500000238418579\n",
      "[61,    10] loss: 0.162\n",
      "[61,    20] loss: 0.083\n",
      "[61,    30] loss: 0.149\n",
      "[61,    40] loss: 0.191\n",
      "[61,    50] loss: 0.175\n",
      "[61,    60] loss: 0.154\n",
      "[61,    70] loss: 0.156\n",
      "[61,    80] loss: 0.127\n",
      "[61,    90] loss: 0.128\n",
      "[61,   100] loss: 0.101\n",
      "[61,   110] loss: 0.078\n",
      "[61,   120] loss: 0.134\n",
      "[batch 9, size: 20] F1 score: 0.949999988079071\n",
      "[batch 19, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 29, size: 20] F1 score: 0.800000011920929\n",
      "[batch 39, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 49, size: 20] F1 score: 0.8500000238418579\n",
      "[62,    10] loss: 0.151\n",
      "[62,    20] loss: 0.093\n",
      "[62,    30] loss: 0.128\n",
      "[62,    40] loss: 0.104\n",
      "[62,    50] loss: 0.122\n",
      "[62,    60] loss: 0.157\n",
      "[62,    70] loss: 0.078\n",
      "[62,    80] loss: 0.098\n",
      "[62,    90] loss: 0.106\n",
      "[62,   100] loss: 0.130\n",
      "[62,   110] loss: 0.075\n",
      "[62,   120] loss: 0.092\n",
      "[batch 9, size: 20] F1 score: 1.0\n",
      "[batch 19, size: 20] F1 score: 0.949999988079071\n",
      "[batch 29, size: 20] F1 score: 0.949999988079071\n",
      "[batch 39, size: 20] F1 score: 0.800000011920929\n",
      "[batch 49, size: 20] F1 score: 0.800000011920929\n",
      "[63,    10] loss: 0.115\n",
      "[63,    20] loss: 0.167\n",
      "[63,    30] loss: 0.174\n",
      "[63,    40] loss: 0.076\n",
      "[63,    50] loss: 0.086\n",
      "[63,    60] loss: 0.118\n",
      "[63,    70] loss: 0.105\n",
      "[63,    80] loss: 0.078\n",
      "[63,    90] loss: 0.070\n",
      "[63,   100] loss: 0.137\n",
      "[63,   110] loss: 0.115\n",
      "[63,   120] loss: 0.133\n",
      "[batch 9, size: 20] F1 score: 1.0\n",
      "[batch 19, size: 20] F1 score: 0.949999988079071\n",
      "[batch 29, size: 20] F1 score: 0.949999988079071\n",
      "[batch 39, size: 20] F1 score: 0.949999988079071\n",
      "[batch 49, size: 20] F1 score: 0.75\n",
      "[64,    10] loss: 0.098\n",
      "[64,    20] loss: 0.135\n",
      "[64,    30] loss: 0.110\n",
      "[64,    40] loss: 0.171\n",
      "[64,    50] loss: 0.093\n",
      "[64,    60] loss: 0.082\n",
      "[64,    70] loss: 0.132\n",
      "[64,    80] loss: 0.108\n",
      "[64,    90] loss: 0.110\n",
      "[64,   100] loss: 0.102\n",
      "[64,   110] loss: 0.112\n",
      "[64,   120] loss: 0.113\n",
      "[batch 9, size: 20] F1 score: 1.0\n",
      "[batch 19, size: 20] F1 score: 0.949999988079071\n",
      "[batch 29, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 39, size: 20] F1 score: 1.0\n",
      "[batch 49, size: 20] F1 score: 0.8500000238418579\n",
      "[65,    10] loss: 0.088\n",
      "[65,    20] loss: 0.104\n",
      "[65,    30] loss: 0.111\n",
      "[65,    40] loss: 0.090\n",
      "[65,    50] loss: 0.068\n",
      "[65,    60] loss: 0.102\n",
      "[65,    70] loss: 0.079\n",
      "[65,    80] loss: 0.114\n",
      "[65,    90] loss: 0.089\n",
      "[65,   100] loss: 0.094\n",
      "[65,   110] loss: 0.138\n",
      "[65,   120] loss: 0.103\n",
      "[batch 9, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 19, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 29, size: 20] F1 score: 0.949999988079071\n",
      "[batch 39, size: 20] F1 score: 0.800000011920929\n",
      "[batch 49, size: 20] F1 score: 0.949999988079071\n",
      "[66,    10] loss: 0.064\n",
      "[66,    20] loss: 0.158\n",
      "[66,    30] loss: 0.137\n",
      "[66,    40] loss: 0.109\n",
      "[66,    50] loss: 0.139\n",
      "[66,    60] loss: 0.099\n",
      "[66,    70] loss: 0.095\n",
      "[66,    80] loss: 0.147\n",
      "[66,    90] loss: 0.082\n",
      "[66,   100] loss: 0.068\n",
      "[66,   110] loss: 0.150\n",
      "[66,   120] loss: 0.085\n",
      "[batch 9, size: 20] F1 score: 0.949999988079071\n",
      "[batch 19, size: 20] F1 score: 0.699999988079071\n",
      "[batch 29, size: 20] F1 score: 0.800000011920929\n",
      "[batch 39, size: 20] F1 score: 0.949999988079071\n",
      "[batch 49, size: 20] F1 score: 0.800000011920929\n",
      "[67,    10] loss: 0.086\n",
      "[67,    20] loss: 0.117\n",
      "[67,    30] loss: 0.071\n",
      "[67,    40] loss: 0.044\n",
      "[67,    50] loss: 0.113\n",
      "[67,    60] loss: 0.069\n",
      "[67,    70] loss: 0.080\n",
      "[67,    80] loss: 0.105\n",
      "[67,    90] loss: 0.101\n",
      "[67,   100] loss: 0.104\n",
      "[67,   110] loss: 0.139\n",
      "[67,   120] loss: 0.107\n",
      "[batch 9, size: 20] F1 score: 0.949999988079071\n",
      "[batch 19, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 29, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 39, size: 20] F1 score: 0.800000011920929\n",
      "[batch 49, size: 20] F1 score: 0.8999999761581421\n",
      "[68,    10] loss: 0.123\n",
      "[68,    20] loss: 0.129\n",
      "[68,    30] loss: 0.116\n",
      "[68,    40] loss: 0.119\n",
      "[68,    50] loss: 0.045\n",
      "[68,    60] loss: 0.115\n",
      "[68,    70] loss: 0.075\n",
      "[68,    80] loss: 0.109\n",
      "[68,    90] loss: 0.065\n",
      "[68,   100] loss: 0.085\n",
      "[68,   110] loss: 0.121\n",
      "[68,   120] loss: 0.127\n",
      "[batch 9, size: 20] F1 score: 0.949999988079071\n",
      "[batch 19, size: 20] F1 score: 0.6499999761581421\n",
      "[batch 29, size: 20] F1 score: 0.949999988079071\n",
      "[batch 39, size: 20] F1 score: 0.6499999761581421\n",
      "[batch 49, size: 20] F1 score: 0.949999988079071\n",
      "[69,    10] loss: 0.088\n",
      "[69,    20] loss: 0.090\n",
      "[69,    30] loss: 0.126\n",
      "[69,    40] loss: 0.121\n",
      "[69,    50] loss: 0.054\n",
      "[69,    60] loss: 0.116\n",
      "[69,    70] loss: 0.072\n",
      "[69,    80] loss: 0.110\n",
      "[69,    90] loss: 0.109\n",
      "[69,   100] loss: 0.101\n",
      "[69,   110] loss: 0.069\n",
      "[69,   120] loss: 0.069\n",
      "[batch 9, size: 20] F1 score: 0.699999988079071\n",
      "[batch 19, size: 20] F1 score: 1.0\n",
      "[batch 29, size: 20] F1 score: 0.75\n",
      "[batch 39, size: 20] F1 score: 1.0\n",
      "[batch 49, size: 20] F1 score: 0.8999999761581421\n",
      "[70,    10] loss: 0.071\n",
      "[70,    20] loss: 0.087\n",
      "[70,    30] loss: 0.088\n",
      "[70,    40] loss: 0.074\n",
      "[70,    50] loss: 0.131\n",
      "[70,    60] loss: 0.085\n",
      "[70,    70] loss: 0.122\n",
      "[70,    80] loss: 0.106\n",
      "[70,    90] loss: 0.060\n",
      "[70,   100] loss: 0.062\n",
      "[70,   110] loss: 0.043\n",
      "[70,   120] loss: 0.055\n",
      "[batch 9, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 19, size: 20] F1 score: 0.75\n",
      "[batch 29, size: 20] F1 score: 1.0\n",
      "[batch 39, size: 20] F1 score: 0.800000011920929\n",
      "[batch 49, size: 20] F1 score: 0.8500000238418579\n",
      "[71,    10] loss: 0.090\n",
      "[71,    20] loss: 0.102\n",
      "[71,    30] loss: 0.084\n",
      "[71,    40] loss: 0.090\n",
      "[71,    50] loss: 0.061\n",
      "[71,    60] loss: 0.062\n",
      "[71,    70] loss: 0.103\n",
      "[71,    80] loss: 0.089\n",
      "[71,    90] loss: 0.061\n",
      "[71,   100] loss: 0.078\n",
      "[71,   110] loss: 0.065\n",
      "[71,   120] loss: 0.088\n",
      "[batch 9, size: 20] F1 score: 0.800000011920929\n",
      "[batch 19, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 29, size: 20] F1 score: 0.800000011920929\n",
      "[batch 39, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 49, size: 20] F1 score: 0.8999999761581421\n",
      "[72,    10] loss: 0.041\n",
      "[72,    20] loss: 0.090\n",
      "[72,    30] loss: 0.080\n",
      "[72,    40] loss: 0.066\n",
      "[72,    50] loss: 0.083\n",
      "[72,    60] loss: 0.091\n",
      "[72,    70] loss: 0.098\n",
      "[72,    80] loss: 0.076\n",
      "[72,    90] loss: 0.099\n",
      "[72,   100] loss: 0.062\n",
      "[72,   110] loss: 0.106\n",
      "[72,   120] loss: 0.117\n",
      "[batch 9, size: 20] F1 score: 0.949999988079071\n",
      "[batch 19, size: 20] F1 score: 0.949999988079071\n",
      "[batch 29, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 39, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 49, size: 20] F1 score: 0.800000011920929\n",
      "[73,    10] loss: 0.059\n",
      "[73,    20] loss: 0.071\n",
      "[73,    30] loss: 0.045\n",
      "[73,    40] loss: 0.060\n",
      "[73,    50] loss: 0.120\n",
      "[73,    60] loss: 0.086\n",
      "[73,    70] loss: 0.099\n",
      "[73,    80] loss: 0.142\n",
      "[73,    90] loss: 0.091\n",
      "[73,   100] loss: 0.062\n",
      "[73,   110] loss: 0.055\n",
      "[73,   120] loss: 0.132\n",
      "[batch 9, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 19, size: 20] F1 score: 0.699999988079071\n",
      "[batch 29, size: 20] F1 score: 0.800000011920929\n",
      "[batch 39, size: 20] F1 score: 0.949999988079071\n",
      "[batch 49, size: 20] F1 score: 0.75\n",
      "[74,    10] loss: 0.102\n",
      "[74,    20] loss: 0.065\n",
      "[74,    30] loss: 0.052\n",
      "[74,    40] loss: 0.100\n",
      "[74,    50] loss: 0.051\n",
      "[74,    60] loss: 0.048\n",
      "[74,    70] loss: 0.047\n",
      "[74,    80] loss: 0.028\n",
      "[74,    90] loss: 0.103\n",
      "[74,   100] loss: 0.066\n",
      "[74,   110] loss: 0.098\n",
      "[74,   120] loss: 0.092\n",
      "[batch 9, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 19, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 29, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 39, size: 20] F1 score: 0.949999988079071\n",
      "[batch 49, size: 20] F1 score: 0.8999999761581421\n",
      "[75,    10] loss: 0.064\n",
      "[75,    20] loss: 0.070\n",
      "[75,    30] loss: 0.032\n",
      "[75,    40] loss: 0.054\n",
      "[75,    50] loss: 0.053\n",
      "[75,    60] loss: 0.031\n",
      "[75,    70] loss: 0.136\n",
      "[75,    80] loss: 0.102\n",
      "[75,    90] loss: 0.063\n",
      "[75,   100] loss: 0.192\n",
      "[75,   110] loss: 0.171\n",
      "[75,   120] loss: 0.094\n",
      "[batch 9, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 19, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 29, size: 20] F1 score: 0.949999988079071\n",
      "[batch 39, size: 20] F1 score: 1.0\n",
      "[batch 49, size: 20] F1 score: 0.8500000238418579\n",
      "[76,    10] loss: 0.080\n",
      "[76,    20] loss: 0.046\n",
      "[76,    30] loss: 0.094\n",
      "[76,    40] loss: 0.069\n",
      "[76,    50] loss: 0.131\n",
      "[76,    60] loss: 0.094\n",
      "[76,    70] loss: 0.062\n",
      "[76,    80] loss: 0.064\n",
      "[76,    90] loss: 0.081\n",
      "[76,   100] loss: 0.113\n",
      "[76,   110] loss: 0.107\n",
      "[76,   120] loss: 0.050\n",
      "[batch 9, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 19, size: 20] F1 score: 0.949999988079071\n",
      "[batch 29, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 39, size: 20] F1 score: 0.800000011920929\n",
      "[batch 49, size: 20] F1 score: 0.8500000238418579\n",
      "[77,    10] loss: 0.064\n",
      "[77,    20] loss: 0.071\n",
      "[77,    30] loss: 0.134\n",
      "[77,    40] loss: 0.096\n",
      "[77,    50] loss: 0.035\n",
      "[77,    60] loss: 0.062\n",
      "[77,    70] loss: 0.150\n",
      "[77,    80] loss: 0.063\n",
      "[77,    90] loss: 0.079\n",
      "[77,   100] loss: 0.083\n",
      "[77,   110] loss: 0.107\n",
      "[77,   120] loss: 0.031\n",
      "[batch 9, size: 20] F1 score: 0.800000011920929\n",
      "[batch 19, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 29, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 39, size: 20] F1 score: 0.949999988079071\n",
      "[batch 49, size: 20] F1 score: 0.800000011920929\n",
      "[78,    10] loss: 0.057\n",
      "[78,    20] loss: 0.081\n",
      "[78,    30] loss: 0.079\n",
      "[78,    40] loss: 0.072\n",
      "[78,    50] loss: 0.060\n",
      "[78,    60] loss: 0.067\n",
      "[78,    70] loss: 0.042\n",
      "[78,    80] loss: 0.043\n",
      "[78,    90] loss: 0.052\n",
      "[78,   100] loss: 0.049\n",
      "[78,   110] loss: 0.041\n",
      "[78,   120] loss: 0.057\n",
      "[batch 9, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 19, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 29, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 39, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 49, size: 20] F1 score: 0.8999999761581421\n",
      "[79,    10] loss: 0.042\n",
      "[79,    20] loss: 0.033\n",
      "[79,    30] loss: 0.042\n",
      "[79,    40] loss: 0.045\n",
      "[79,    50] loss: 0.049\n",
      "[79,    60] loss: 0.089\n",
      "[79,    70] loss: 0.035\n",
      "[79,    80] loss: 0.050\n",
      "[79,    90] loss: 0.071\n",
      "[79,   100] loss: 0.040\n",
      "[79,   110] loss: 0.062\n",
      "[79,   120] loss: 0.061\n",
      "[batch 9, size: 20] F1 score: 1.0\n",
      "[batch 19, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 29, size: 20] F1 score: 0.949999988079071\n",
      "[batch 39, size: 20] F1 score: 1.0\n",
      "[batch 49, size: 20] F1 score: 0.8999999761581421\n",
      "[80,    10] loss: 0.056\n",
      "[80,    20] loss: 0.023\n",
      "[80,    30] loss: 0.058\n",
      "[80,    40] loss: 0.047\n",
      "[80,    50] loss: 0.044\n",
      "[80,    60] loss: 0.064\n",
      "[80,    70] loss: 0.073\n",
      "[80,    80] loss: 0.060\n",
      "[80,    90] loss: 0.087\n",
      "[80,   100] loss: 0.054\n",
      "[80,   110] loss: 0.070\n",
      "[80,   120] loss: 0.098\n",
      "[batch 9, size: 20] F1 score: 0.949999988079071\n",
      "[batch 19, size: 20] F1 score: 0.75\n",
      "[batch 29, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 39, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 49, size: 20] F1 score: 0.800000011920929\n",
      "[81,    10] loss: 0.042\n",
      "[81,    20] loss: 0.110\n",
      "[81,    30] loss: 0.088\n",
      "[81,    40] loss: 0.082\n",
      "[81,    50] loss: 0.097\n",
      "[81,    60] loss: 0.028\n",
      "[81,    70] loss: 0.084\n",
      "[81,    80] loss: 0.103\n",
      "[81,    90] loss: 0.066\n",
      "[81,   100] loss: 0.061\n",
      "[81,   110] loss: 0.090\n",
      "[81,   120] loss: 0.084\n",
      "[batch 9, size: 20] F1 score: 0.800000011920929\n",
      "[batch 19, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 29, size: 20] F1 score: 1.0\n",
      "[batch 39, size: 20] F1 score: 0.800000011920929\n",
      "[batch 49, size: 20] F1 score: 0.8500000238418579\n",
      "[82,    10] loss: 0.082\n",
      "[82,    20] loss: 0.081\n",
      "[82,    30] loss: 0.072\n",
      "[82,    40] loss: 0.117\n",
      "[82,    50] loss: 0.093\n",
      "[82,    60] loss: 0.055\n",
      "[82,    70] loss: 0.048\n",
      "[82,    80] loss: 0.098\n",
      "[82,    90] loss: 0.054\n",
      "[82,   100] loss: 0.036\n",
      "[82,   110] loss: 0.039\n",
      "[82,   120] loss: 0.039\n",
      "[batch 9, size: 20] F1 score: 0.75\n",
      "[batch 19, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 29, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 39, size: 20] F1 score: 0.949999988079071\n",
      "[batch 49, size: 20] F1 score: 0.8999999761581421\n",
      "[83,    10] loss: 0.027\n",
      "[83,    20] loss: 0.045\n",
      "[83,    30] loss: 0.056\n",
      "[83,    40] loss: 0.045\n",
      "[83,    50] loss: 0.048\n",
      "[83,    60] loss: 0.043\n",
      "[83,    70] loss: 0.028\n",
      "[83,    80] loss: 0.087\n",
      "[83,    90] loss: 0.043\n",
      "[83,   100] loss: 0.052\n",
      "[83,   110] loss: 0.042\n",
      "[83,   120] loss: 0.091\n",
      "[batch 9, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 19, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 29, size: 20] F1 score: 0.75\n",
      "[batch 39, size: 20] F1 score: 0.949999988079071\n",
      "[batch 49, size: 20] F1 score: 0.8500000238418579\n",
      "[84,    10] loss: 0.079\n",
      "[84,    20] loss: 0.062\n",
      "[84,    30] loss: 0.039\n",
      "[84,    40] loss: 0.063\n",
      "[84,    50] loss: 0.044\n",
      "[84,    60] loss: 0.056\n",
      "[84,    70] loss: 0.038\n",
      "[84,    80] loss: 0.014\n",
      "[84,    90] loss: 0.087\n",
      "[84,   100] loss: 0.071\n",
      "[84,   110] loss: 0.048\n",
      "[84,   120] loss: 0.033\n",
      "[batch 9, size: 20] F1 score: 0.75\n",
      "[batch 19, size: 20] F1 score: 0.949999988079071\n",
      "[batch 29, size: 20] F1 score: 0.949999988079071\n",
      "[batch 39, size: 20] F1 score: 0.949999988079071\n",
      "[batch 49, size: 20] F1 score: 1.0\n",
      "[85,    10] loss: 0.036\n",
      "[85,    20] loss: 0.091\n",
      "[85,    30] loss: 0.097\n",
      "[85,    40] loss: 0.098\n",
      "[85,    50] loss: 0.111\n",
      "[85,    60] loss: 0.120\n",
      "[85,    70] loss: 0.079\n",
      "[85,    80] loss: 0.109\n",
      "[85,    90] loss: 0.038\n",
      "[85,   100] loss: 0.036\n",
      "[85,   110] loss: 0.058\n",
      "[85,   120] loss: 0.080\n",
      "[batch 9, size: 20] F1 score: 0.800000011920929\n",
      "[batch 19, size: 20] F1 score: 0.949999988079071\n",
      "[batch 29, size: 20] F1 score: 0.800000011920929\n",
      "[batch 39, size: 20] F1 score: 0.949999988079071\n",
      "[batch 49, size: 20] F1 score: 0.949999988079071\n",
      "[86,    10] loss: 0.071\n",
      "[86,    20] loss: 0.026\n",
      "[86,    30] loss: 0.046\n",
      "[86,    40] loss: 0.037\n",
      "[86,    50] loss: 0.025\n",
      "[86,    60] loss: 0.049\n",
      "[86,    70] loss: 0.057\n",
      "[86,    80] loss: 0.032\n",
      "[86,    90] loss: 0.033\n",
      "[86,   100] loss: 0.056\n",
      "[86,   110] loss: 0.057\n",
      "[86,   120] loss: 0.059\n",
      "[batch 9, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 19, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 29, size: 20] F1 score: 0.75\n",
      "[batch 39, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 49, size: 20] F1 score: 0.949999988079071\n",
      "[87,    10] loss: 0.032\n",
      "[87,    20] loss: 0.035\n",
      "[87,    30] loss: 0.079\n",
      "[87,    40] loss: 0.061\n",
      "[87,    50] loss: 0.054\n",
      "[87,    60] loss: 0.045\n",
      "[87,    70] loss: 0.060\n",
      "[87,    80] loss: 0.049\n",
      "[87,    90] loss: 0.068\n",
      "[87,   100] loss: 0.024\n",
      "[87,   110] loss: 0.037\n",
      "[87,   120] loss: 0.051\n",
      "[batch 9, size: 20] F1 score: 0.949999988079071\n",
      "[batch 19, size: 20] F1 score: 0.949999988079071\n",
      "[batch 29, size: 20] F1 score: 0.75\n",
      "[batch 39, size: 20] F1 score: 0.949999988079071\n",
      "[batch 49, size: 20] F1 score: 0.800000011920929\n",
      "[88,    10] loss: 0.081\n",
      "[88,    20] loss: 0.071\n",
      "[88,    30] loss: 0.071\n",
      "[88,    40] loss: 0.044\n",
      "[88,    50] loss: 0.025\n",
      "[88,    60] loss: 0.033\n",
      "[88,    70] loss: 0.034\n",
      "[88,    80] loss: 0.026\n",
      "[88,    90] loss: 0.059\n",
      "[88,   100] loss: 0.042\n",
      "[88,   110] loss: 0.022\n",
      "[88,   120] loss: 0.058\n",
      "[batch 9, size: 20] F1 score: 0.949999988079071\n",
      "[batch 19, size: 20] F1 score: 0.800000011920929\n",
      "[batch 29, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 39, size: 20] F1 score: 0.949999988079071\n",
      "[batch 49, size: 20] F1 score: 1.0\n",
      "[89,    10] loss: 0.042\n",
      "[89,    20] loss: 0.034\n",
      "[89,    30] loss: 0.041\n",
      "[89,    40] loss: 0.050\n",
      "[89,    50] loss: 0.042\n",
      "[89,    60] loss: 0.116\n",
      "[89,    70] loss: 0.070\n",
      "[89,    80] loss: 0.019\n",
      "[89,    90] loss: 0.046\n",
      "[89,   100] loss: 0.033\n",
      "[89,   110] loss: 0.068\n",
      "[89,   120] loss: 0.036\n",
      "[batch 9, size: 20] F1 score: 0.949999988079071\n",
      "[batch 19, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 29, size: 20] F1 score: 0.949999988079071\n",
      "[batch 39, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 49, size: 20] F1 score: 0.949999988079071\n",
      "[90,    10] loss: 0.052\n",
      "[90,    20] loss: 0.037\n",
      "[90,    30] loss: 0.039\n",
      "[90,    40] loss: 0.042\n",
      "[90,    50] loss: 0.052\n",
      "[90,    60] loss: 0.063\n",
      "[90,    70] loss: 0.057\n",
      "[90,    80] loss: 0.041\n",
      "[90,    90] loss: 0.062\n",
      "[90,   100] loss: 0.062\n",
      "[90,   110] loss: 0.022\n",
      "[90,   120] loss: 0.064\n",
      "[batch 9, size: 20] F1 score: 0.949999988079071\n",
      "[batch 19, size: 20] F1 score: 0.800000011920929\n",
      "[batch 29, size: 20] F1 score: 0.949999988079071\n",
      "[batch 39, size: 20] F1 score: 0.949999988079071\n",
      "[batch 49, size: 20] F1 score: 0.8999999761581421\n",
      "[91,    10] loss: 0.025\n",
      "[91,    20] loss: 0.053\n",
      "[91,    30] loss: 0.042\n",
      "[91,    40] loss: 0.028\n",
      "[91,    50] loss: 0.052\n",
      "[91,    60] loss: 0.022\n",
      "[91,    70] loss: 0.037\n",
      "[91,    80] loss: 0.060\n",
      "[91,    90] loss: 0.031\n",
      "[91,   100] loss: 0.046\n",
      "[91,   110] loss: 0.072\n",
      "[91,   120] loss: 0.096\n",
      "[batch 9, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 19, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 29, size: 20] F1 score: 1.0\n",
      "[batch 39, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 49, size: 20] F1 score: 1.0\n",
      "[92,    10] loss: 0.047\n",
      "[92,    20] loss: 0.015\n",
      "[92,    30] loss: 0.033\n",
      "[92,    40] loss: 0.073\n",
      "[92,    50] loss: 0.048\n",
      "[92,    60] loss: 0.041\n",
      "[92,    70] loss: 0.031\n",
      "[92,    80] loss: 0.048\n",
      "[92,    90] loss: 0.095\n",
      "[92,   100] loss: 0.069\n",
      "[92,   110] loss: 0.042\n",
      "[92,   120] loss: 0.062\n",
      "[batch 9, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 19, size: 20] F1 score: 0.75\n",
      "[batch 29, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 39, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 49, size: 20] F1 score: 0.8999999761581421\n",
      "[93,    10] loss: 0.038\n",
      "[93,    20] loss: 0.039\n",
      "[93,    30] loss: 0.059\n",
      "[93,    40] loss: 0.049\n",
      "[93,    50] loss: 0.038\n",
      "[93,    60] loss: 0.047\n",
      "[93,    70] loss: 0.046\n",
      "[93,    80] loss: 0.043\n",
      "[93,    90] loss: 0.020\n",
      "[93,   100] loss: 0.026\n",
      "[93,   110] loss: 0.084\n",
      "[93,   120] loss: 0.042\n",
      "[batch 9, size: 20] F1 score: 0.949999988079071\n",
      "[batch 19, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 29, size: 20] F1 score: 0.75\n",
      "[batch 39, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 49, size: 20] F1 score: 1.0\n",
      "[94,    10] loss: 0.037\n",
      "[94,    20] loss: 0.040\n",
      "[94,    30] loss: 0.036\n",
      "[94,    40] loss: 0.031\n",
      "[94,    50] loss: 0.029\n",
      "[94,    60] loss: 0.048\n",
      "[94,    70] loss: 0.038\n",
      "[94,    80] loss: 0.114\n",
      "[94,    90] loss: 0.067\n",
      "[94,   100] loss: 0.031\n",
      "[94,   110] loss: 0.050\n",
      "[94,   120] loss: 0.049\n",
      "[batch 9, size: 20] F1 score: 1.0\n",
      "[batch 19, size: 20] F1 score: 1.0\n",
      "[batch 29, size: 20] F1 score: 0.949999988079071\n",
      "[batch 39, size: 20] F1 score: 0.800000011920929\n",
      "[batch 49, size: 20] F1 score: 0.949999988079071\n",
      "[95,    10] loss: 0.080\n",
      "[95,    20] loss: 0.044\n",
      "[95,    30] loss: 0.015\n",
      "[95,    40] loss: 0.023\n",
      "[95,    50] loss: 0.030\n",
      "[95,    60] loss: 0.012\n",
      "[95,    70] loss: 0.066\n",
      "[95,    80] loss: 0.055\n",
      "[95,    90] loss: 0.033\n",
      "[95,   100] loss: 0.060\n",
      "[95,   110] loss: 0.028\n",
      "[95,   120] loss: 0.044\n",
      "[batch 9, size: 20] F1 score: 0.800000011920929\n",
      "[batch 19, size: 20] F1 score: 0.949999988079071\n",
      "[batch 29, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 39, size: 20] F1 score: 0.949999988079071\n",
      "[batch 49, size: 20] F1 score: 1.0\n",
      "[96,    10] loss: 0.042\n",
      "[96,    20] loss: 0.074\n",
      "[96,    30] loss: 0.026\n",
      "[96,    40] loss: 0.034\n",
      "[96,    50] loss: 0.022\n",
      "[96,    60] loss: 0.049\n",
      "[96,    70] loss: 0.045\n",
      "[96,    80] loss: 0.032\n",
      "[96,    90] loss: 0.062\n",
      "[96,   100] loss: 0.048\n",
      "[96,   110] loss: 0.061\n",
      "[96,   120] loss: 0.062\n",
      "[batch 9, size: 20] F1 score: 1.0\n",
      "[batch 19, size: 20] F1 score: 0.800000011920929\n",
      "[batch 29, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 39, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 49, size: 20] F1 score: 0.8999999761581421\n",
      "[97,    10] loss: 0.024\n",
      "[97,    20] loss: 0.023\n",
      "[97,    30] loss: 0.030\n",
      "[97,    40] loss: 0.022\n",
      "[97,    50] loss: 0.033\n",
      "[97,    60] loss: 0.044\n",
      "[97,    70] loss: 0.044\n",
      "[97,    80] loss: 0.019\n",
      "[97,    90] loss: 0.069\n",
      "[97,   100] loss: 0.048\n",
      "[97,   110] loss: 0.025\n",
      "[97,   120] loss: 0.035\n",
      "[batch 9, size: 20] F1 score: 0.75\n",
      "[batch 19, size: 20] F1 score: 0.949999988079071\n",
      "[batch 29, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 39, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 49, size: 20] F1 score: 0.800000011920929\n",
      "[98,    10] loss: 0.026\n",
      "[98,    20] loss: 0.039\n",
      "[98,    30] loss: 0.018\n",
      "[98,    40] loss: 0.034\n",
      "[98,    50] loss: 0.039\n",
      "[98,    60] loss: 0.030\n",
      "[98,    70] loss: 0.017\n",
      "[98,    80] loss: 0.024\n",
      "[98,    90] loss: 0.022\n",
      "[98,   100] loss: 0.037\n",
      "[98,   110] loss: 0.037\n",
      "[98,   120] loss: 0.041\n",
      "[batch 9, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 19, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 29, size: 20] F1 score: 1.0\n",
      "[batch 39, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 49, size: 20] F1 score: 0.8500000238418579\n",
      "[99,    10] loss: 0.031\n",
      "[99,    20] loss: 0.017\n",
      "[99,    30] loss: 0.053\n",
      "[99,    40] loss: 0.029\n",
      "[99,    50] loss: 0.061\n",
      "[99,    60] loss: 0.043\n",
      "[99,    70] loss: 0.054\n",
      "[99,    80] loss: 0.061\n",
      "[99,    90] loss: 0.050\n",
      "[99,   100] loss: 0.043\n",
      "[99,   110] loss: 0.049\n",
      "[99,   120] loss: 0.032\n",
      "[batch 9, size: 20] F1 score: 0.949999988079071\n",
      "[batch 19, size: 20] F1 score: 1.0\n",
      "[batch 29, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 39, size: 20] F1 score: 0.800000011920929\n",
      "[batch 49, size: 20] F1 score: 0.8500000238418579\n",
      "[100,    10] loss: 0.034\n",
      "[100,    20] loss: 0.047\n",
      "[100,    30] loss: 0.016\n",
      "[100,    40] loss: 0.035\n",
      "[100,    50] loss: 0.027\n",
      "[100,    60] loss: 0.027\n",
      "[100,    70] loss: 0.042\n",
      "[100,    80] loss: 0.018\n",
      "[100,    90] loss: 0.024\n",
      "[100,   100] loss: 0.040\n",
      "[100,   110] loss: 0.049\n",
      "[100,   120] loss: 0.031\n",
      "[batch 9, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 19, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 29, size: 20] F1 score: 1.0\n",
      "[batch 39, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 49, size: 20] F1 score: 0.8999999761581421\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    net.train()\n",
    "    for i, data in enumerate(dl_train, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 9:    # print every 30 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 10:.3f}')\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    predictions_list = [] #list for predictions (predicted number of label)\n",
    "    values_list = []      #list for values (actual number of label)\n",
    "    f1_list = np.zeros(len(dl_test))\n",
    "    net.eval()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(dl_test, 0):\n",
    "        inputs, labels = data\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        f1_list[i] = F1(outputs, labels).item()\n",
    "        if i % 10 == 9:    # print every 10 mini-batches\n",
    "            print(f\"[batch {i}, size: {dl_test.batch_size}] F1 score: {f1_list[i]}\")\n",
    "    \n",
    "    epochs_F1List[0][epoch] = f1_list.mean()\n",
    "    epochs_F1List[1][epoch] = f1_list.std()\n",
    "    \n",
    "    if epochs_F1List[0][epoch] > f1_max:\n",
    "        torch.save(net.state_dict(), \"model.ebr\")\n",
    "        f1_max=epochs_F1List[0][epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "0.9017857100282397\n",
      "[0.07194013]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Finished Training')\n",
    "\n",
    "\n",
    "plt.plot(epochs_F1List[0])\n",
    "print(epochs_F1List[0].max())\n",
    "\n",
    "ind = np.where(epochs_F1List[0]==epochs_F1List[0].max())\n",
    "print(epochs_F1List[1][ind])\n",
    "plt.savefig(\"f1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[batch 9, size: 20] F1 score: 0.949999988079071\n",
      "[batch 19, size: 20] F1 score: 0.8500000238418579\n",
      "[batch 29, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 39, size: 20] F1 score: 0.8999999761581421\n",
      "[batch 49, size: 20] F1 score: 0.8500000238418579\n",
      "tensor([0.7297, 0.3226, 0.9628, 0.1250, 0.8755, 0.8313])\n",
      "tensor([[ 27,   0,   0,   0,   1,   9],\n",
      "        [  0,  10,  19,   0,   0,   2],\n",
      "        [  0,   1, 569,   0,   0,  21],\n",
      "        [  0,   1,   3,   2,   7,   3],\n",
      "        [  2,   1,  15,   5, 232,  10],\n",
      "        [  2,   5,  19,   2,   0, 138]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mcr = MulticlassRecall(num_classes=6, average=None)\n",
    "mccm = MulticlassConfusionMatrix(num_classes=6)\n",
    "\n",
    "net.eval()\n",
    "out = None\n",
    "lab = None\n",
    "f1_list = np.zeros(len(dl_test))\n",
    "running_loss = 0.0\n",
    "for i, data in enumerate(dl_test, 0):\n",
    "    inputs, labels = data\n",
    "    # forward + backward + optimize\n",
    "    outputs = net(inputs)\n",
    "\n",
    "\n",
    "    if out is None:\n",
    "        out = outputs.detach()\n",
    "    else:\n",
    "        out = np.vstack((out, outputs.detach()))\n",
    "\n",
    "    if lab is None:\n",
    "        lab = labels.detach()\n",
    "    else:\n",
    "        lab = np.hstack((lab, labels.detach()))\n",
    "    f1_list[i] = F1(outputs, labels).item()\n",
    "    if i % 10 == 9:    # print every 10 mini-batches\n",
    "        print(f\"[batch {i}, size: {dl_test.batch_size}] F1 score: {f1_list[i]}\")\n",
    "\n",
    "print(mcr(torch.Tensor(out), torch.Tensor(lab)))\n",
    "print(mccm(torch.Tensor(out), torch.Tensor(lab)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
